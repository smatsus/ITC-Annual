\begin{雑誌論文}{1}
\bibitem{LMY01}
T. Lee, S. Matsushima, K. Yamanishi: “Grafting for combinatorial binary model using frequent itemset mining,” Data Mining and Knowledge Discovery, 34(1), pp. 101-123 (2020)
\bibitem{FMY01}
Y. Fu, S. Matsushima, K. Yamanishi: “Model Selection for Non-Negative Tensor Factorization with Minimum Description Length,” Entropy 2019, 21, 632.
\end{雑誌論文}
\begin{査読付}{1}
\bibitem{HSM02}
S. Hayashi, M. Sugiyama, S. Matsushima: “Coordinate Descent Method for Log-linear Model on Posets,”  In Proceedings of IEEE International Conference on Data Science and Advanced Analytics (DSAA), pp. 99-108 (2020)
\bibitem{MB01}
S. Matsushima, M. Brbić: “Selective Sampling-based Scalable Sparse Subspace Clustering,” Advances in Neural Information Processing Systems (NeurIPS). pp. 12416-12425 (2019)
\bibitem{RSMZYV01}
P. Raman, S. Srinivasan, S. Matsushima, X. Zhang, H. Yun, S. V. N. Vishwanathan: “Scaling Multinomial Logistic Regression via Hybrid Parallelism,” ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), pp. 1460-1470 (2019)

\end{査読付}

\begin{発表}{1}
\bibitem{KM01} 上月正貴、松島慎「二変数間の相互作用を考慮した一般化加法モデルの効率的な学習」第22回情報論的学習理論ワークショップ、名古屋、2019年11月
\bibitem{HSM01} 林翔太、杉山麿人、松島慎「半順序構造上の対数線形モデルのための座標降下法」第22回情報論的学習理論ワークショップ、名古屋、2019年11月
\bibitem{NM01} 西本洋紀、松島慎「対数線形モデルを基とした生成的分類器と識別的分類器のロジスティック汎化誤差の収束の比較」第23回情報論的学習理論ワークショップ、オンライン、2020年11月
\bibitem{KM02} 上月正貴、松島慎「二変数間相互作用を考慮した一般化加法モデルとその効率的な学習」科研費シンポジウム機械学習・統計学・最適化の数理とAI技術への展開、オンライン、2020年12月
\end{発表}

